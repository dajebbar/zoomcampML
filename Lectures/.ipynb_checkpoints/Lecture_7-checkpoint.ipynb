{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCbHmJKes66A"
   },
   "source": [
    "# From Model to BentoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHlLOnieszZ9"
   },
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "n65KtCXxselW"
   },
   "outputs": [],
   "source": [
    "#!wget https://github.com/gastonstat/CreditScoring/raw/master/CreditScoring.csv --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnLGcQ2LtFkD"
   },
   "source": [
    "**Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HUtJtCzws52F"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ehp/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "import xgboost as xgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dxkBWcH9tIYP"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('CreditScoring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cwIgI-CztM5o"
   },
   "outputs": [],
   "source": [
    "# make all columns in lower\n",
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Y8_gIpwstRvi"
   },
   "outputs": [],
   "source": [
    "# mapping the target\n",
    "df['status'] = df['status'].map({\n",
    "    1:'ok',\n",
    "    2:'default',\n",
    "    0:'unk'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UwNk3aO8thOh"
   },
   "outputs": [],
   "source": [
    "# mapping categorical features\n",
    "def mapping_categorical(df, cat, cat_lst):\n",
    "  to_lst = df[cat].value_counts().sort_index().index.to_list()\n",
    "  cat_lst = cat_lst\n",
    "\n",
    "  df[cat] = (\n",
    "      df[cat].map({\n",
    "          k:v for (k,v) in zip(to_lst, cat_lst)\n",
    "      })\n",
    "   )\n",
    "\n",
    "cols = ['home', 'marital', 'records', 'job']\n",
    "\n",
    "home_lst = ['unk', 'rent', 'owner', 'private', 'ignore', 'parents', 'other']\n",
    "marital_lst = ['unk', 'single', 'married', 'widow', 'separated', 'divorced']\n",
    "records_lst = ['no', 'yes', 'unk']\n",
    "job_lst = ['unk', 'fixed', 'partime', 'freelance', 'others']\n",
    "cat_lst = [home_lst, marital_lst, records_lst, job_lst]\n",
    "\n",
    "for col, cat in zip(cols, cat_lst):\n",
    "  mapping_categorical(df, col, cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kDXHSgxHtv8F"
   },
   "outputs": [],
   "source": [
    "# fix missing values\n",
    "def fix_missing_values(df, val_to_rep, rep, *f_lst):\n",
    "  for f in f_lst:\n",
    "    df[f] = df[f].replace(val_to_rep, rep)\n",
    "\n",
    "fix_missing_values(df, 99999999.0, np.nan, ['income', 'assets', 'debt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5yi8zsQot_KZ"
   },
   "outputs": [],
   "source": [
    "# don't nees unk in status\n",
    "df = df[df.status != 'unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "boC92xE-uNEi"
   },
   "outputs": [],
   "source": [
    "# data preparation\n",
    "data, target = df.drop(columns=['status']), df['status'].map({'ok':0, 'default':1})\n",
    "\n",
    "def tweaking(data, target):\n",
    "  numerical = selector(dtype_include=np.number)(data)\n",
    "  categorical = selector(dtype_include=object)(data)\n",
    "\n",
    "  num_imputer = SimpleImputer(missing_values=np.NaN, strategy='constant', fill_value=0)\n",
    "  cat_imputer = SimpleImputer(strategy='most_frequent', fill_value='unk')\n",
    "  cat_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "  \n",
    "  X_full_train, X_test, y_full_train, y_test = model_selection.train_test_split(\n",
    "      data,\n",
    "      target,\n",
    "      test_size=.2,\n",
    "      random_state=11,\n",
    "    )\n",
    "  X_train, X_dev, y_train, y_dev = model_selection.train_test_split(\n",
    "          X_full_train,\n",
    "          y_full_train,\n",
    "          test_size=.25,\n",
    "          random_state=11,\n",
    "        )\n",
    "\n",
    "\n",
    "  X_train.loc[:, numerical] = num_imputer.fit_transform(X_train[numerical])\n",
    "  X_train.loc[:, categorical] = cat_imputer.fit_transform(X_train[categorical])\n",
    "  X_train.loc[:, categorical] = cat_encoder.fit_transform(X_train[categorical])\n",
    "\n",
    "  X_dev.loc[:, numerical] = num_imputer.transform(X_dev[numerical])\n",
    "  X_dev.loc[:, categorical] = cat_imputer.transform(X_dev[categorical])\n",
    "  X_dev.loc[:, categorical] = cat_encoder.transform(X_dev[categorical])\n",
    "\n",
    "  X_test.loc[:, numerical] = num_imputer.transform(X_test[numerical])\n",
    "  X_test.loc[:, categorical] = cat_imputer.transform(X_test[categorical])\n",
    "  X_test.loc[:, categorical] = cat_encoder.transform(X_test[categorical])\n",
    "\n",
    "  return X_train, y_train, X_dev, y_dev, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lcgzZtH7wEnq"
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_dev, y_dev, X_test, y_test = tweaking(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VlxaHHZmvZ7y",
    "outputId": "84ec8f29-63f6-47f4-8715-8f5b98e576a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:47:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[04:47:34] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8121897023564457"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrap data into DMatrix â€” a special\n",
    "# data structure for finding splits efficiently.\n",
    "dtrain = xgb.DMatrix(\n",
    "    X_train.values, \n",
    "    label=y_train.values, \n",
    "    feature_names=X_train.columns\n",
    ")\n",
    "\n",
    "# for validation\n",
    "dval = xgb.DMatrix(\n",
    "    X_dev.values,\n",
    "    label=y_dev.values,\n",
    "    feature_names=X_dev.columns\n",
    ")\n",
    "\n",
    "# specifying the parameters for training\n",
    "xgb_params = {\n",
    "    'eta':.3,\n",
    "    'max_depth':6,\n",
    "    'min_child_weight': 1,\n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': -1,\n",
    "    'seed': 1,\n",
    "    'silent':1\n",
    "}\n",
    "\n",
    "# For training an XGBoost model, we use the train function\n",
    "model = xgb.train(\n",
    "    xgb_params,\n",
    "    dtrain,\n",
    "    num_boost_round=10\n",
    ")\n",
    "\n",
    "y_pred = model.predict(dval)\n",
    "metrics.roc_auc_score(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HZS-pKfNxJhx",
    "outputId": "912b6a30-3207-4f1c-8926-ad6b15cc204e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:47:34] WARNING: ../src/learner.cc:576: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-auc:0.76600\tdev-auc:0.73459\n",
      "[10]\ttrain-auc:0.82062\tdev-auc:0.76979\n",
      "[20]\ttrain-auc:0.83677\tdev-auc:0.78571\n",
      "[30]\ttrain-auc:0.84640\tdev-auc:0.79379\n",
      "[40]\ttrain-auc:0.85774\tdev-auc:0.80618\n",
      "[50]\ttrain-auc:0.86499\tdev-auc:0.81203\n",
      "[60]\ttrain-auc:0.86914\tdev-auc:0.81505\n",
      "[70]\ttrain-auc:0.87350\tdev-auc:0.81941\n",
      "[80]\ttrain-auc:0.87660\tdev-auc:0.82213\n",
      "[90]\ttrain-auc:0.87878\tdev-auc:0.82233\n",
      "[100]\ttrain-auc:0.88088\tdev-auc:0.82450\n",
      "[110]\ttrain-auc:0.88243\tdev-auc:0.82651\n",
      "[120]\ttrain-auc:0.88379\tdev-auc:0.82784\n",
      "[130]\ttrain-auc:0.88528\tdev-auc:0.82841\n",
      "[140]\ttrain-auc:0.88664\tdev-auc:0.82930\n",
      "[150]\ttrain-auc:0.88783\tdev-auc:0.82986\n",
      "[160]\ttrain-auc:0.88901\tdev-auc:0.83080\n",
      "[170]\ttrain-auc:0.89029\tdev-auc:0.83164\n",
      "[180]\ttrain-auc:0.89147\tdev-auc:0.83222\n",
      "[190]\ttrain-auc:0.89237\tdev-auc:0.83242\n",
      "[200]\ttrain-auc:0.89308\tdev-auc:0.83276\n",
      "[210]\ttrain-auc:0.89387\tdev-auc:0.83305\n",
      "[220]\ttrain-auc:0.89457\tdev-auc:0.83317\n",
      "[230]\ttrain-auc:0.89533\tdev-auc:0.83336\n",
      "[240]\ttrain-auc:0.89599\tdev-auc:0.83336\n",
      "[250]\ttrain-auc:0.89655\tdev-auc:0.83359\n",
      "[260]\ttrain-auc:0.89714\tdev-auc:0.83362\n",
      "[270]\ttrain-auc:0.89776\tdev-auc:0.83387\n",
      "[280]\ttrain-auc:0.89835\tdev-auc:0.83411\n",
      "[290]\ttrain-auc:0.89897\tdev-auc:0.83428\n",
      "[300]\ttrain-auc:0.89952\tdev-auc:0.83462\n",
      "[310]\ttrain-auc:0.90008\tdev-auc:0.83478\n",
      "[320]\ttrain-auc:0.90056\tdev-auc:0.83478\n",
      "[330]\ttrain-auc:0.90115\tdev-auc:0.83452\n",
      "[340]\ttrain-auc:0.90164\tdev-auc:0.83481\n",
      "[350]\ttrain-auc:0.90229\tdev-auc:0.83498\n",
      "[360]\ttrain-auc:0.90294\tdev-auc:0.83493\n",
      "[370]\ttrain-auc:0.90355\tdev-auc:0.83482\n",
      "[380]\ttrain-auc:0.90435\tdev-auc:0.83446\n",
      "[390]\ttrain-auc:0.90502\tdev-auc:0.83422\n",
      "[400]\ttrain-auc:0.90563\tdev-auc:0.83414\n",
      "[410]\ttrain-auc:0.90614\tdev-auc:0.83376\n",
      "[420]\ttrain-auc:0.90658\tdev-auc:0.83368\n",
      "[430]\ttrain-auc:0.90715\tdev-auc:0.83351\n",
      "[440]\ttrain-auc:0.90755\tdev-auc:0.83351\n",
      "[450]\ttrain-auc:0.90798\tdev-auc:0.83344\n",
      "[460]\ttrain-auc:0.90842\tdev-auc:0.83331\n",
      "[470]\ttrain-auc:0.90893\tdev-auc:0.83363\n",
      "[480]\ttrain-auc:0.90949\tdev-auc:0.83321\n",
      "[490]\ttrain-auc:0.90988\tdev-auc:0.83318\n",
      "[499]\ttrain-auc:0.91011\tdev-auc:0.83336\n"
     ]
    }
   ],
   "source": [
    "watchlist = [(dtrain, 'train'), (dval, 'dev')]\n",
    "\n",
    "xgb_params = {\n",
    "    'eta':.05,\n",
    "    'max_depth':3,\n",
    "    'min_child_weight': 30,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'nthread': -1,\n",
    "    'seed': 1,\n",
    "    'silent':1\n",
    "}\n",
    "\n",
    "model = xgb.train(\n",
    "    xgb_params,\n",
    "    dtrain,\n",
    "    num_boost_round=500,\n",
    "    evals=watchlist,\n",
    "    verbose_eval=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEm5z7TQxhum",
    "outputId": "a1ffbd57-d6ed-4d96-abb4-55e30fd5fb2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-dev:  0.833\n",
      "AUC-test:  0.820\n"
     ]
    }
   ],
   "source": [
    "dtest = xgb.DMatrix(\n",
    "    X_test.values,\n",
    "    label=y_test.values, \n",
    "    feature_names=X_test.columns\n",
    ")\n",
    "\n",
    "y_pred_dev = model.predict(dval)\n",
    "y_pred_test = model.predict(dtest)\n",
    "\n",
    "print(f\"AUC-dev: {metrics.roc_auc_score(y_dev, y_pred_dev): .3f}\")\n",
    "print(f\"AUC-test: {metrics.roc_auc_score(y_test, y_pred_test): .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcSMjL-ox5mJ",
    "outputId": "d761653a-809a-4c15-8c87-a2a724a6bf08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8329749279116367"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full_train = pd.concat([X_train, X_dev])\n",
    "y_full_train = pd.concat([y_train, y_dev])\n",
    "\n",
    "dfulltrain = xgb.DMatrix(\n",
    "    X_full_train.values, \n",
    "    label=y_full_train.values, \n",
    "    feature_names=X_full_train.columns\n",
    ")\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.1, \n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dfulltrain, num_boost_round=175)\n",
    "\n",
    "y_pred = model.predict(dtest)\n",
    "metrics.roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N78ug_Ee7YsU",
    "outputId": "c853e4ad-51f2-449e-8a4e-544bf3f1117b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bentoml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbentoml\u001b[39;00m\n\u001b[1;32m      4\u001b[0m bentoml\u001b[38;5;241m.\u001b[39mxgboost\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcredit_risk_model\u001b[39m\u001b[38;5;124m\"\u001b[39m, model)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bentoml'"
     ]
    }
   ],
   "source": [
    "import bentoml\n",
    "\n",
    "bentoml.xgboost.save_model(\"credit_risk_model\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGVTxhU97pnq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
