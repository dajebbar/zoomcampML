{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP-r9bFhNOj6",
        "outputId": "5bcc715f-9b16-41f4-bc01-9d5743cc90b2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 348 kB 7.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 209 kB 44.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 48.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 44.0 MB/s \n",
            "\u001b[?25h  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tnQkMR3EMr0s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import make_column_selector as selector\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn import tree\n",
        "from sklearn import ensemble\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.dummy import DummyClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import optuna\n",
        "pd.options.display.max_columns = 30\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('creditScoreCleaned.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tQcTdtaCNX9e",
        "outputId": "b220417d-2258-49c8-8e8d-8e8500110f88"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    status  seniority   home  time  age  marital records        job  expenses  \\\n",
              "0       ok          9   rent    60   30  married      no  freelance        73   \n",
              "1       ok         17   rent    60   58    widow      no      fixed        48   \n",
              "2  default         10  owner    36   46  married     yes  freelance        90   \n",
              "3       ok          0   rent    60   24   single      no      fixed        63   \n",
              "4       ok          0   rent    36   26   single      no      fixed        46   \n",
              "\n",
              "   income  assets  debt  amount  price  \n",
              "0   129.0     0.0   0.0     800    846  \n",
              "1   131.0     0.0   0.0    1000   1658  \n",
              "2   200.0  3000.0   0.0    2000   2985  \n",
              "3   182.0  2500.0   0.0     900   1325  \n",
              "4   107.0     0.0   0.0     310    910  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4bd1fc9-10bb-407f-aafc-3e3b5f005533\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>status</th>\n",
              "      <th>seniority</th>\n",
              "      <th>home</th>\n",
              "      <th>time</th>\n",
              "      <th>age</th>\n",
              "      <th>marital</th>\n",
              "      <th>records</th>\n",
              "      <th>job</th>\n",
              "      <th>expenses</th>\n",
              "      <th>income</th>\n",
              "      <th>assets</th>\n",
              "      <th>debt</th>\n",
              "      <th>amount</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ok</td>\n",
              "      <td>9</td>\n",
              "      <td>rent</td>\n",
              "      <td>60</td>\n",
              "      <td>30</td>\n",
              "      <td>married</td>\n",
              "      <td>no</td>\n",
              "      <td>freelance</td>\n",
              "      <td>73</td>\n",
              "      <td>129.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>800</td>\n",
              "      <td>846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ok</td>\n",
              "      <td>17</td>\n",
              "      <td>rent</td>\n",
              "      <td>60</td>\n",
              "      <td>58</td>\n",
              "      <td>widow</td>\n",
              "      <td>no</td>\n",
              "      <td>fixed</td>\n",
              "      <td>48</td>\n",
              "      <td>131.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000</td>\n",
              "      <td>1658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>default</td>\n",
              "      <td>10</td>\n",
              "      <td>owner</td>\n",
              "      <td>36</td>\n",
              "      <td>46</td>\n",
              "      <td>married</td>\n",
              "      <td>yes</td>\n",
              "      <td>freelance</td>\n",
              "      <td>90</td>\n",
              "      <td>200.0</td>\n",
              "      <td>3000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2000</td>\n",
              "      <td>2985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ok</td>\n",
              "      <td>0</td>\n",
              "      <td>rent</td>\n",
              "      <td>60</td>\n",
              "      <td>24</td>\n",
              "      <td>single</td>\n",
              "      <td>no</td>\n",
              "      <td>fixed</td>\n",
              "      <td>63</td>\n",
              "      <td>182.0</td>\n",
              "      <td>2500.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>900</td>\n",
              "      <td>1325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ok</td>\n",
              "      <td>0</td>\n",
              "      <td>rent</td>\n",
              "      <td>36</td>\n",
              "      <td>26</td>\n",
              "      <td>single</td>\n",
              "      <td>no</td>\n",
              "      <td>fixed</td>\n",
              "      <td>46</td>\n",
              "      <td>107.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>310</td>\n",
              "      <td>910</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4bd1fc9-10bb-407f-aafc-3e3b5f005533')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4bd1fc9-10bb-407f-aafc-3e3b5f005533 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4bd1fc9-10bb-407f-aafc-3e3b5f005533');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gyvKW2VNoaF",
        "outputId": "240f78f3-a6ae-4faa-d95a-a8fa0dedc522"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4454, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data, target = df.drop(columns=['status']), df['status'].map({'ok':0, 'default':1})"
      ],
      "metadata": {
        "id": "3xTfiVCaN0xL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tweaking(data=data, target=target, linreg=False):\n",
        "    X = data.copy()\n",
        "    y = target.copy()\n",
        "\n",
        "    numerical = selector(dtype_include=np.number)(X)\n",
        "    categorical = selector(dtype_include=object)(X)\n",
        "\n",
        "    sca = StandardScaler()\n",
        "\n",
        "    num_imputer = SimpleImputer(\n",
        "        missing_values=np.NaN, \n",
        "        strategy='constant', \n",
        "        fill_value=0\n",
        "    )\n",
        "    cat_imputer = SimpleImputer(\n",
        "        strategy='most_frequent', \n",
        "        fill_value='unk'\n",
        "    )\n",
        "    cat_ord_encoder = OrdinalEncoder(\n",
        "        handle_unknown='use_encoded_value', \n",
        "        unknown_value=-1\n",
        "    )\n",
        "    cat_ohe = OneHotEncoder(\n",
        "        sparse=False,\n",
        "        handle_unknown='ignore'\n",
        "    )\n",
        "\n",
        "    X_full_train, X_test, y_full_train, y_test = model_selection.train_test_split(\n",
        "      X,\n",
        "      y,\n",
        "      test_size=.2,\n",
        "      random_state=42,\n",
        "    )\n",
        "    X_train, X_dev, y_train, y_dev = model_selection.train_test_split(\n",
        "          X_full_train,\n",
        "          y_full_train,\n",
        "          test_size=.25,\n",
        "          random_state=42,\n",
        "    )\n",
        "\n",
        "    X_train.loc[:, numerical] = num_imputer.fit_transform(X_train[numerical])\n",
        "    X_dev.loc[:, numerical] = num_imputer.transform(X_dev[numerical])\n",
        "    X_test.loc[:, numerical] = num_imputer.transform(X_test[numerical])\n",
        "\n",
        "    X_train.loc[:, categorical] = cat_imputer.fit_transform(X_train[categorical])\n",
        "    X_dev.loc[:, categorical] = cat_imputer.transform(X_dev[categorical])\n",
        "    X_test.loc[:, categorical] = cat_imputer.transform(X_test[categorical])\n",
        "    \n",
        "    if linreg:\n",
        "        X_train.loc[:, numerical] = sca.fit_transform(X_train[numerical])\n",
        "        X_dev.loc[:, numerical] = sca.transform(X_dev[numerical])\n",
        "        X_test.loc[:, numerical] = sca.transform(X_test[numerical])\n",
        "\n",
        "\n",
        "        cat_encoded = cat_ohe.fit_transform(X_train[categorical])\n",
        "        features = cat_ohe.get_feature_names_out(categorical)\n",
        "        cat_encoded = pd.DataFrame(cat_encoded, columns=features)\n",
        "        X_train.reset_index(inplace=True, drop=True)\n",
        "        X_train = X_train[numerical].join(cat_encoded)\n",
        "\n",
        "        cat_encoded = cat_ohe.transform(X_dev[categorical])\n",
        "        cat_encoded = pd.DataFrame(cat_encoded, columns=features)\n",
        "        X_dev.reset_index(inplace=True, drop=True)\n",
        "        X_dev = X_dev[numerical].join(cat_encoded)\n",
        "\n",
        "        cat_encoded = cat_ohe.transform(X_test[categorical])\n",
        "        cat_encoded = pd.DataFrame(cat_encoded, columns=features)\n",
        "        X_test.reset_index(inplace=True, drop=True)\n",
        "        X_test = X_test[numerical].join(cat_encoded)\n",
        "\n",
        "    else:\n",
        "        \n",
        "        X_train.loc[:, categorical] = cat_ord_encoder.fit_transform(X_train[categorical])\n",
        "        X_dev.loc[:, categorical] = cat_ord_encoder.transform(X_dev[categorical])\n",
        "        X_test.loc[:, categorical] = cat_ord_encoder.transform(X_test[categorical])\n",
        "       \n",
        "    \n",
        "    return X_train, y_train, X_dev, y_dev, X_test, y_test"
      ],
      "metadata": {
        "id": "J1ity3oDNvJ_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "    DummyClassifier,\n",
        "    LogisticRegression,\n",
        "    GaussianNB,\n",
        "    SVC,\n",
        "    KNeighborsClassifier,\n",
        "]\n",
        "\n",
        "X_train, y_train, X_dev, y_dev, X_test, y_test = tweaking(linreg=True)\n",
        "\n",
        "X = pd.concat([X_train, X_dev])\n",
        "y = pd.concat([y_train, y_dev])\n",
        "\n",
        "for model in models:\n",
        "    cls = model()\n",
        "    kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    cv_results = model_selection.cross_val_score(\n",
        "        cls,\n",
        "        X,\n",
        "        y,\n",
        "        cv=kf,\n",
        "        scoring=\"roc_auc\",\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"{model.__name__:22} AUC: \"\n",
        "        f\"{cv_results.mean():.3f} STD: {cv_results.std():.2f}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OqA2XUbOGn3",
        "outputId": "6d39f648-eb25-4fef-f28d-32948ba11036"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DummyClassifier        AUC: 0.500 STD: 0.00\n",
            "LogisticRegression     AUC: 0.840 STD: 0.02\n",
            "GaussianNB             AUC: 0.780 STD: 0.02\n",
            "SVC                    AUC: 0.842 STD: 0.02\n",
            "KNeighborsClassifier   AUC: 0.749 STD: 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    classifier_name = trial.suggest_categorical(\"classifier\", [\"logit\", \"svc\"])\n",
        "\n",
        "    if classifier_name == \"logit\":\n",
        "        logit_penalty = trial.suggest_categorical(\"logit_penalty\", [\"l1\", \"l2\"])\n",
        "        logit_c = trial.suggest_float(\"logit_c\", 0.001, 10)\n",
        "        logit_solver = trial.suggest_categorical(\"logit_solver\", [\"saga\"])\n",
        "\n",
        "        model = LogisticRegression(\n",
        "            penalty=logit_penalty,\n",
        "            C=logit_c,\n",
        "            solver=logit_solver,\n",
        "            max_iter=1000\n",
        "        )\n",
        "    \n",
        "    elif classifier_name == \"svc\":\n",
        "        svc_c = trial.suggest_float(\"svc_c\", 0.001, 10)\n",
        "        svc_gamma = trial.suggest_categorical(\"svc_gamma\", [\"scale\", \"auto\"])\n",
        "        svc_class_weight = trial.suggest_categorical(\"svc_class_weight\", [\"balanced\", None])\n",
        "\n",
        "        model = SVC(\n",
        "            C=svc_c,\n",
        "            gamma=svc_gamma,\n",
        "            class_weight=svc_class_weight\n",
        "        )\n",
        "\n",
        "    kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    score = model_selection.cross_val_score(\n",
        "        model,\n",
        "        X,\n",
        "        y,\n",
        "        cv=kf,\n",
        "        scoring=\"roc_auc\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    auc = score.mean()\n",
        "\n",
        "    return auc\n",
        "\n",
        "# TPE sampler the default\n",
        "study = optuna.create_study(\n",
        "    direction=\"maximize\",\n",
        "    # sampler=optuna.samplers.TPESampler()\n",
        "    # sampler=optuna.samplers.RandomSampler()\n",
        "    sampler=optuna.samplers.CmaEsSampler()\n",
        ")\n",
        "\n",
        "study.optimize(objective, n_trials=20)\n",
        "print(\"CMA-ES\")\n",
        "print(f\"CMA-ES best params: {study.best_params}\")\n",
        "print(f\"CMA-ES best score: {study.best_value}\")\n",
        "print()\n",
        "result = study.trials_dataframe()\n",
        "print(result[\"params_classifier\"].value_counts())\n",
        "res = result.groupby([\"params_classifier\"])[\"value\"].agg([\"mean\", \"std\"])\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MkD2vNGOvkZ",
        "outputId": "b5fd0327-2c8a-4e5b-e3ea-f92b711855b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-10-19 07:55:08,529]\u001b[0m A new study created in memory with name: no-name-c787734d-6efd-4911-822f-7ebd38a861fc\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:55:15,461]\u001b[0m Trial 0 finished with value: 0.8399754303991326 and parameters: {'classifier': 'logit', 'logit_penalty': 'l2', 'logit_c': 8.374371697729224, 'logit_solver': 'saga'}. Best is trial 0 with value: 0.8399754303991326.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:55:15,465]\u001b[0m `CmaEsSampler` only supports two or more dimensional continuous search space. `RandomSampler` is used instead of `CmaEsSampler`.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:55:17,619]\u001b[0m Trial 1 finished with value: 0.840760815908507 and parameters: {'classifier': 'svc', 'svc_c': 5.158246495377517, 'svc_gamma': 'auto', 'svc_class_weight': None}. Best is trial 1 with value: 0.840760815908507.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:55:19,428]\u001b[0m Trial 2 finished with value: 0.8403276158980887 and parameters: {'classifier': 'svc', 'svc_c': 1.2845548670344171, 'svc_gamma': 'scale', 'svc_class_weight': None}. Best is trial 1 with value: 0.840760815908507.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:55:21,270]\u001b[0m Trial 3 finished with value: 0.841459000850648 and parameters: {'classifier': 'svc', 'svc_c': 4.505637913132781, 'svc_gamma': 'auto', 'svc_class_weight': None}. Best is trial 3 with value: 0.841459000850648.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:55:26,803]\u001b[0m Trial 4 finished with value: 0.8399693869647615 and parameters: {'classifier': 'logit', 'logit_penalty': 'l2', 'logit_c': 7.9783585169298545, 'logit_solver': 'saga'}. Best is trial 3 with value: 0.841459000850648.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:55:33,955]\u001b[0m Trial 5 finished with value: 0.8399682015967805 and parameters: {'classifier': 'logit', 'logit_penalty': 'l1', 'logit_c': 8.61692387395931, 'logit_solver': 'saga'}. Best is trial 3 with value: 0.841459000850648.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:55:38,551]\u001b[0m Trial 6 finished with value: 0.8402673521394872 and parameters: {'classifier': 'logit', 'logit_penalty': 'l1', 'logit_c': 2.2365995294529384, 'logit_solver': 'saga'}. Best is trial 3 with value: 0.841459000850648.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:55:40,350]\u001b[0m Trial 7 finished with value: 0.8436323657090009 and parameters: {'classifier': 'svc', 'svc_c': 0.6237647236965644, 'svc_gamma': 'scale', 'svc_class_weight': None}. Best is trial 7 with value: 0.8436323657090009.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:55:42,656]\u001b[0m Trial 8 finished with value: 0.8305611012526771 and parameters: {'classifier': 'svc', 'svc_c': 5.936930117793429, 'svc_gamma': 'scale', 'svc_class_weight': 'balanced'}. Best is trial 7 with value: 0.8436323657090009.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:55:49,805]\u001b[0m Trial 9 finished with value: 0.8399970042037946 and parameters: {'classifier': 'logit', 'logit_penalty': 'l1', 'logit_c': 7.421806668356317, 'logit_solver': 'saga'}. Best is trial 7 with value: 0.8436323657090009.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:55:55,444]\u001b[0m Trial 10 finished with value: 0.8399754303991326 and parameters: {'classifier': 'logit', 'logit_penalty': 'l2', 'logit_c': 8.401180121133256, 'logit_solver': 'saga'}. Best is trial 7 with value: 0.8436323657090009.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:56:02,312]\u001b[0m Trial 11 finished with value: 0.8400129713583043 and parameters: {'classifier': 'logit', 'logit_penalty': 'l2', 'logit_c': 2.2257902566989283, 'logit_solver': 'saga'}. Best is trial 7 with value: 0.8436323657090009.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:56:05,712]\u001b[0m Trial 12 finished with value: 0.8375572115484363 and parameters: {'classifier': 'svc', 'svc_c': 8.267807264733388, 'svc_gamma': 'auto', 'svc_class_weight': None}. Best is trial 7 with value: 0.8436323657090009.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:56:15,332]\u001b[0m Trial 13 finished with value: 0.840047155044628 and parameters: {'classifier': 'logit', 'logit_penalty': 'l1', 'logit_c': 5.144863224113225, 'logit_solver': 'saga'}. Best is trial 7 with value: 0.8436323657090009.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:56:17,223]\u001b[0m Trial 14 finished with value: 0.8398881381197114 and parameters: {'classifier': 'svc', 'svc_c': 5.917113657287717, 'svc_gamma': 'auto', 'svc_class_weight': None}. Best is trial 7 with value: 0.8436323657090009.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:56:22,812]\u001b[0m Trial 15 finished with value: 0.839971502015589 and parameters: {'classifier': 'logit', 'logit_penalty': 'l2', 'logit_c': 7.148818211523594, 'logit_solver': 'saga'}. Best is trial 7 with value: 0.8436323657090009.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:56:24,639]\u001b[0m Trial 16 finished with value: 0.8407625651693561 and parameters: {'classifier': 'svc', 'svc_c': 5.121905100432138, 'svc_gamma': 'auto', 'svc_class_weight': None}. Best is trial 7 with value: 0.8436323657090009.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:56:26,988]\u001b[0m Trial 17 finished with value: 0.8303246129364711 and parameters: {'classifier': 'svc', 'svc_c': 6.024981894847851, 'svc_gamma': 'scale', 'svc_class_weight': 'balanced'}. Best is trial 7 with value: 0.8436323657090009.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:56:34,107]\u001b[0m Trial 18 finished with value: 0.8399496154405206 and parameters: {'classifier': 'logit', 'logit_penalty': 'l1', 'logit_c': 9.293388059912534, 'logit_solver': 'saga'}. Best is trial 7 with value: 0.8436323657090009.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 07:56:43,213]\u001b[0m Trial 19 finished with value: 0.8400984664994302 and parameters: {'classifier': 'logit', 'logit_penalty': 'l1', 'logit_c': 3.9134134275339942, 'logit_solver': 'saga'}. Best is trial 7 with value: 0.8436323657090009.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CMA-ES\n",
            "CMA-ES best params: {'classifier': 'svc', 'svc_c': 0.6237647236965644, 'svc_gamma': 'scale', 'svc_class_weight': None}\n",
            "CMA-ES best score: 0.8436323657090009\n",
            "\n",
            "logit    11\n",
            "svc       9\n",
            "Name: params_classifier, dtype: int64\n",
            "                       mean       std\n",
            "params_classifier                    \n",
            "logit              0.840021  0.000092\n",
            "svc                0.838364  0.004759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dv = DictVectorizer(sparse=False, sort=False)\n",
        "X_dict = X.to_dict(orient=\"records\")\n",
        "X_test_dict = X_test.to_dict(orient=\"records\")\n",
        "X = dv.fit_transform(X_dict)\n",
        "X_test = dv.transform(X_test_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejM_HWg9PSyC",
        "outputId": "6ebdd267-14ab-4e70-93ea-875f31779eee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-test:  0.684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(\n",
        "    C=2.2257902566989283,\n",
        "    penalty='l2',\n",
        "    solver='saga'\n",
        ")\n",
        "model.fit(X, y)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(f\"AUC-test: {metrics.roc_auc_score(y_test, y_pred): .3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trRey6_rQFsW",
        "outputId": "0c6de947-3f6d-48ba-8289-4584537555ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-test:  0.703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def twk(data=data, target=target):\n",
        "  X = data.copy()\n",
        "  y = target.copy()\n",
        "\n",
        "  numerical = selector(dtype_include=np.number)(X)\n",
        "  categorical = selector(dtype_include=object)(X)\n",
        "  \n",
        "  num_imputer = SimpleImputer(\n",
        "        missing_values=np.NaN, \n",
        "        strategy='constant', \n",
        "        fill_value=0\n",
        "    )\n",
        "  cat_ord_encoder = OrdinalEncoder(\n",
        "        handle_unknown='use_encoded_value', \n",
        "        unknown_value=-1\n",
        "    )\n",
        "    \n",
        "  X_full_train, X_test, y_full_train, y_test = model_selection.train_test_split(\n",
        "      X,\n",
        "      y,\n",
        "      test_size=.2,\n",
        "      random_state=42,\n",
        "    )\n",
        "  X_train, X_dev, y_train, y_dev = model_selection.train_test_split(\n",
        "          X_full_train,\n",
        "          y_full_train,\n",
        "          test_size=.25,\n",
        "          random_state=42,\n",
        "    )\n",
        "\n",
        "  X_train.loc[:, numerical] = num_imputer.fit_transform(X_train[numerical])\n",
        "  X_dev.loc[:, numerical] = num_imputer.transform(X_dev[numerical])\n",
        "  X_test.loc[:, numerical] = num_imputer.transform(X_test[numerical])\n",
        "  X_train.loc[:, categorical] = cat_ord_encoder.fit_transform(X_train[categorical])\n",
        "  X_dev.loc[:, categorical] = cat_ord_encoder.transform(X_dev[categorical])\n",
        "  X_test.loc[:, categorical] = cat_ord_encoder.transform(X_test[categorical])\n",
        "  \n",
        "  return X_train, y_train, X_dev, y_dev, X_test, y_test"
      ],
      "metadata": {
        "id": "TZwt28cVQsPz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_dev, y_dev, X_test, y_test = twk()\n",
        "\n",
        "X = pd.concat([X_train, X_dev])\n",
        "y = pd.concat([y_train, y_test])\n",
        "\n",
        "X.shape, y.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2acWyipLR1on",
        "outputId": "d10b5803-c896-4be7-e057-0608aeee5639"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3563, 13), (3563,), (891, 13), (891,))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "    tree.DecisionTreeClassifier,\n",
        "    ensemble.HistGradientBoostingClassifier,\n",
        "    ensemble.RandomForestClassifier,\n",
        "    xgb.XGBClassifier,\n",
        "]\n",
        "\n",
        "for model in models:\n",
        "    cls = model()\n",
        "    kf = model_selection.KFold(n_splits=10, shuffle=True, random_state=11)\n",
        "    cv_results = model_selection.cross_val_score(\n",
        "        cls,\n",
        "        X,\n",
        "        y,\n",
        "        cv=kf,\n",
        "        scoring=\"roc_auc\",\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        f\"{model.__name__:22} AUC: \"\n",
        "        f\"{cv_results.mean():.3f} STD: {cv_results.std():.2f}\"\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MYEAiM-SL9R",
        "outputId": "f1f1faab-ff93-4d52-b9ae-a9b0250dcc6a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier AUC: 0.613 STD: 0.03\n",
            "HistGradientBoostingClassifier AUC: 0.732 STD: 0.03\n",
            "RandomForestClassifier AUC: 0.745 STD: 0.02\n",
            "XGBClassifier          AUC: 0.754 STD: 0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    classifier_name = trial.suggest_categorical(\"classifier\", [\"hist\", \"rf\", \"xgb\"])\n",
        "\n",
        "    if classifier_name == \"hist\":\n",
        "        hist_learning_rate = trial.suggest_float(\"hist_learning_rate\", 0.001, 0.5)\n",
        "        hist_max_iter = trial.suggest_int(\"hist_max_iter\", 10, 250)\n",
        "        hist_max_leaf_nodes = trial.suggest_int(\"hist_max_leaf_nodes\", 10, 150)\n",
        "\n",
        "        model = ensemble.HistGradientBoostingClassifier(\n",
        "            learning_rate=hist_learning_rate,\n",
        "            max_iter=hist_max_iter,\n",
        "            max_leaf_nodes=hist_max_leaf_nodes\n",
        "        )\n",
        "    \n",
        "    elif classifier_name == \"rf\":\n",
        "        rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 100, 1000)\n",
        "        rf_criterion = trial.suggest_categorical(\"rf_criterion\", ['gini', 'entropy'])\n",
        "        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 1, 4)\n",
        "        rf_min_samples_split = trial.suggest_float(\"rf_min_samples_split\", 0.01, 1)\n",
        "\n",
        "        model = ensemble.RandomForestClassifier(\n",
        "            n_estimators=rf_n_estimators,\n",
        "            criterion=rf_criterion,\n",
        "            max_depth=rf_max_depth,\n",
        "            min_samples_split=rf_min_samples_split,\n",
        "        )\n",
        "    \n",
        "    elif classifier_name == \"xgb\":\n",
        "        xgb_eta = trial.suggest_float(\"xgb_eta\", 0.001, 0.5)\n",
        "        xgb_max_depth = trial.suggest_int(\"xgb_max_depth\", 1, 15)\n",
        "        xgb_min_child_weight = trial.suggest_int(\"xgb_min_child_weight\", 1, 15)\n",
        "        model = xgb.XGBClassifier(\n",
        "            eta=xgb_eta,\n",
        "            max_depth=xgb_max_depth,\n",
        "            min_child_weight=xgb_min_child_weight,\n",
        "            objective=\"binary:logistic\",\n",
        "            nthread=-1,\n",
        "        )\n",
        "\n",
        "    kf = model_selection.KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "    score = model_selection.cross_val_score(\n",
        "        model,\n",
        "        X,\n",
        "        y,\n",
        "        cv=kf,\n",
        "        scoring=\"roc_auc\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    auc = score.mean()\n",
        "\n",
        "    return auc"
      ],
      "metadata": {
        "id": "lWc9PfnHSaWL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(\n",
        "    direction=\"maximize\",\n",
        "    # sampler=optuna.samplers.TPESampler()\n",
        "    sampler=optuna.samplers.RandomSampler()\n",
        "    # sampler=optuna.samplers.CmaEsSampler()\n",
        ")\n",
        "\n",
        "study.optimize(objective, n_trials=100)\n",
        "print(\"Randomized Sample\")\n",
        "print(f\"RS best params: {study.best_params}\")\n",
        "print(f\"RS best score: {study.best_value}\")\n",
        "print()\n",
        "result = study.trials_dataframe()\n",
        "print(result[\"params_classifier\"].value_counts())\n",
        "res = result.groupby([\"params_classifier\"])[\"value\"].agg([\"mean\", \"std\"])\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtIjKuRITTHy",
        "outputId": "5ab8d135-6aec-4ac7-bdc6-3809401206f6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-10-19 08:13:23,489]\u001b[0m A new study created in memory with name: no-name-df884ae9-0bb3-4721-9a2f-204d1874fae8\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:13:27,835]\u001b[0m Trial 0 finished with value: 0.7444540109174858 and parameters: {'classifier': 'rf', 'rf_n_estimators': 201, 'rf_criterion': 'entropy', 'rf_max_depth': 3, 'rf_min_samples_split': 0.1633299799462796}. Best is trial 0 with value: 0.7444540109174858.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:13:28,675]\u001b[0m Trial 1 finished with value: 0.7535292616066737 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.15187700453016306, 'xgb_max_depth': 3, 'xgb_min_child_weight': 10}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:13:30,575]\u001b[0m Trial 2 finished with value: 0.5 and parameters: {'classifier': 'rf', 'rf_n_estimators': 264, 'rf_criterion': 'entropy', 'rf_max_depth': 4, 'rf_min_samples_split': 0.6780127039386767}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:13:31,220]\u001b[0m Trial 3 finished with value: 0.753210187708983 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.21144409150167653, 'xgb_max_depth': 2, 'xgb_min_child_weight': 1}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:13:37,915]\u001b[0m Trial 4 finished with value: 0.7327981792486189 and parameters: {'classifier': 'rf', 'rf_n_estimators': 702, 'rf_criterion': 'entropy', 'rf_max_depth': 3, 'rf_min_samples_split': 0.513960130851216}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:13:39,930]\u001b[0m Trial 5 finished with value: 0.6860975953570749 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.44636627246524285, 'hist_max_iter': 58, 'hist_max_leaf_nodes': 52}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:13:40,586]\u001b[0m Trial 6 finished with value: 0.753210187708983 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.12246551334640839, 'xgb_max_depth': 2, 'xgb_min_child_weight': 1}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:13:49,325]\u001b[0m Trial 7 finished with value: 0.6917199315106844 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.32801745930529924, 'hist_max_iter': 222, 'hist_max_leaf_nodes': 80}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:13:50,522]\u001b[0m Trial 8 finished with value: 0.7050534672376971 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.29618100999964475, 'hist_max_iter': 65, 'hist_max_leaf_nodes': 37}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:13:52,747]\u001b[0m Trial 9 finished with value: 0.7345709703011043 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.20826512438353922, 'xgb_max_depth': 10, 'xgb_min_child_weight': 9}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:13:54,394]\u001b[0m Trial 10 finished with value: 0.5 and parameters: {'classifier': 'rf', 'rf_n_estimators': 227, 'rf_criterion': 'entropy', 'rf_max_depth': 1, 'rf_min_samples_split': 0.9693503723509186}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:13:56,506]\u001b[0m Trial 11 finished with value: 0.6900453333934393 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.48444836316763906, 'hist_max_iter': 82, 'hist_max_leaf_nodes': 57}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:13:57,971]\u001b[0m Trial 12 finished with value: 0.7032657753635381 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.47443035608451506, 'hist_max_iter': 35, 'hist_max_leaf_nodes': 89}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:14:00,115]\u001b[0m Trial 13 finished with value: 0.7368328816646279 and parameters: {'classifier': 'rf', 'rf_n_estimators': 240, 'rf_criterion': 'gini', 'rf_max_depth': 2, 'rf_min_samples_split': 0.25030920097572096}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:14:03,946]\u001b[0m Trial 14 finished with value: 0.72615288682337 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.06197934024839655, 'hist_max_iter': 61, 'hist_max_leaf_nodes': 123}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:14:06,782]\u001b[0m Trial 15 finished with value: 0.7196483195685429 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.2735221785857629, 'xgb_max_depth': 10, 'xgb_min_child_weight': 3}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:14:12,685]\u001b[0m Trial 16 finished with value: 0.6965887031076031 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.43695396714490925, 'hist_max_iter': 148, 'hist_max_leaf_nodes': 118}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:14:13,686]\u001b[0m Trial 17 finished with value: 0.7513846261749325 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.47745126390627307, 'xgb_max_depth': 4, 'xgb_min_child_weight': 11}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:14:22,339]\u001b[0m Trial 18 finished with value: 0.7323731070927002 and parameters: {'classifier': 'rf', 'rf_n_estimators': 858, 'rf_criterion': 'entropy', 'rf_max_depth': 1, 'rf_min_samples_split': 0.41965399507810275}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:14:32,054]\u001b[0m Trial 19 finished with value: 0.7113287005269249 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.1064602018260028, 'hist_max_iter': 168, 'hist_max_leaf_nodes': 141}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:14:32,510]\u001b[0m Trial 20 finished with value: 0.7498149168896463 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.26409596463011115, 'xgb_max_depth': 1, 'xgb_min_child_weight': 3}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:14:34,293]\u001b[0m Trial 21 finished with value: 0.7022542316847812 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.1817653938769433, 'hist_max_iter': 201, 'hist_max_leaf_nodes': 17}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:14:35,907]\u001b[0m Trial 22 finished with value: 0.7407843995430571 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.00899751120403872, 'xgb_max_depth': 7, 'xgb_min_child_weight': 12}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:14:37,850]\u001b[0m Trial 23 finished with value: 0.7343615762224497 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.36309460205525695, 'xgb_max_depth': 9, 'xgb_min_child_weight': 14}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:14:38,714]\u001b[0m Trial 24 finished with value: 0.7190683794432193 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.2132880689702999, 'hist_max_iter': 119, 'hist_max_leaf_nodes': 12}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:14:39,338]\u001b[0m Trial 25 finished with value: 0.7142606133020761 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.3210211252317355, 'hist_max_iter': 12, 'hist_max_leaf_nodes': 105}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:14:43,977]\u001b[0m Trial 26 finished with value: 0.690046583698468 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.2536639032263794, 'hist_max_iter': 202, 'hist_max_leaf_nodes': 33}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:14:55,442]\u001b[0m Trial 27 finished with value: 0.7327938938881347 and parameters: {'classifier': 'rf', 'rf_n_estimators': 856, 'rf_criterion': 'gini', 'rf_max_depth': 3, 'rf_min_samples_split': 0.6205864230232527}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:14:58,445]\u001b[0m Trial 28 finished with value: 0.7279396598767182 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.10236185281815849, 'xgb_max_depth': 11, 'xgb_min_child_weight': 7}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:01,965]\u001b[0m Trial 29 finished with value: 0.7202024835273626 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.48204482370415175, 'xgb_max_depth': 11, 'xgb_min_child_weight': 3}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:03,771]\u001b[0m Trial 30 finished with value: 0.7265053196340158 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.053234747212169885, 'xgb_max_depth': 7, 'xgb_min_child_weight': 2}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:09,228]\u001b[0m Trial 31 finished with value: 0.7025418739011858 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.10670551754953606, 'hist_max_iter': 250, 'hist_max_leaf_nodes': 49}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:14,037]\u001b[0m Trial 32 finished with value: 0.5 and parameters: {'classifier': 'rf', 'rf_n_estimators': 686, 'rf_criterion': 'gini', 'rf_max_depth': 1, 'rf_min_samples_split': 0.7880893344492308}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:19,930]\u001b[0m Trial 33 finished with value: 0.5 and parameters: {'classifier': 'rf', 'rf_n_estimators': 833, 'rf_criterion': 'gini', 'rf_max_depth': 2, 'rf_min_samples_split': 0.8066128890564279}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:21,543]\u001b[0m Trial 34 finished with value: 0.702768874004868 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.4709059835087846, 'hist_max_iter': 35, 'hist_max_leaf_nodes': 133}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:26,105]\u001b[0m Trial 35 finished with value: 0.7365782558912974 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.01147026383763327, 'hist_max_iter': 113, 'hist_max_leaf_nodes': 97}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:27,289]\u001b[0m Trial 36 finished with value: 0.7022346753759192 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.38489971768757714, 'hist_max_iter': 129, 'hist_max_leaf_nodes': 17}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:29,660]\u001b[0m Trial 37 finished with value: 0.7335522571799429 and parameters: {'classifier': 'rf', 'rf_n_estimators': 278, 'rf_criterion': 'gini', 'rf_max_depth': 2, 'rf_min_samples_split': 0.4924131038064873}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:38,251]\u001b[0m Trial 38 finished with value: 0.7030798943799871 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.20892490723243604, 'hist_max_iter': 193, 'hist_max_leaf_nodes': 123}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:45,381]\u001b[0m Trial 39 finished with value: 0.7067462108300744 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.10303073245147547, 'hist_max_iter': 193, 'hist_max_leaf_nodes': 88}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:45,906]\u001b[0m Trial 40 finished with value: 0.7195800766774807 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.26807033192112956, 'hist_max_iter': 79, 'hist_max_leaf_nodes': 10}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:47,648]\u001b[0m Trial 41 finished with value: 0.6870855140289162 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.3436974650768513, 'hist_max_iter': 211, 'hist_max_leaf_nodes': 15}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:48,623]\u001b[0m Trial 42 finished with value: 0.6987876420389532 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.3436706067504775, 'hist_max_iter': 45, 'hist_max_leaf_nodes': 44}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:51,473]\u001b[0m Trial 43 finished with value: 0.728049016352851 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.31135692298117496, 'xgb_max_depth': 15, 'xgb_min_child_weight': 8}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:53,848]\u001b[0m Trial 44 finished with value: 0.690918726063321 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.4192465233594707, 'hist_max_iter': 168, 'hist_max_leaf_nodes': 30}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:55,382]\u001b[0m Trial 45 finished with value: 0.5 and parameters: {'classifier': 'rf', 'rf_n_estimators': 208, 'rf_criterion': 'gini', 'rf_max_depth': 4, 'rf_min_samples_split': 0.8157209848562094}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:57,669]\u001b[0m Trial 46 finished with value: 0.7326349801745702 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.15302689491969992, 'xgb_max_depth': 11, 'xgb_min_child_weight': 11}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:15:58,789]\u001b[0m Trial 47 finished with value: 0.6941228871244186 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.43700172427492767, 'hist_max_iter': 102, 'hist_max_leaf_nodes': 21}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:01,429]\u001b[0m Trial 48 finished with value: 0.7429235334104172 and parameters: {'classifier': 'rf', 'rf_n_estimators': 280, 'rf_criterion': 'gini', 'rf_max_depth': 3, 'rf_min_samples_split': 0.21136833290818283}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:04,580]\u001b[0m Trial 49 finished with value: 0.7148426369162453 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.16662313845409274, 'xgb_max_depth': 11, 'xgb_min_child_weight': 1}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:06,478]\u001b[0m Trial 50 finished with value: 0.5 and parameters: {'classifier': 'rf', 'rf_n_estimators': 259, 'rf_criterion': 'entropy', 'rf_max_depth': 4, 'rf_min_samples_split': 0.9507525104903826}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:08,137]\u001b[0m Trial 51 finished with value: 0.738679883445455 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.20931152110863477, 'xgb_max_depth': 7, 'xgb_min_child_weight': 11}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:12,726]\u001b[0m Trial 52 finished with value: 0.6885641825062219 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.41332513277016586, 'hist_max_iter': 175, 'hist_max_leaf_nodes': 59}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:15,189]\u001b[0m Trial 53 finished with value: 0.730548714811785 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.0652210225326514, 'xgb_max_depth': 11, 'xgb_min_child_weight': 8}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:19,678]\u001b[0m Trial 54 finished with value: 0.7219901239744402 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.0698384995528399, 'hist_max_iter': 97, 'hist_max_leaf_nodes': 115}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:26,667]\u001b[0m Trial 55 finished with value: 0.6954086394685294 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.31058189765966976, 'hist_max_iter': 190, 'hist_max_leaf_nodes': 87}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:33,794]\u001b[0m Trial 56 finished with value: 0.7316816366789112 and parameters: {'classifier': 'rf', 'rf_n_estimators': 907, 'rf_criterion': 'gini', 'rf_max_depth': 1, 'rf_min_samples_split': 0.17060626527743006}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:34,243]\u001b[0m Trial 57 finished with value: 0.7498149168896463 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.4590808904418519, 'xgb_max_depth': 1, 'xgb_min_child_weight': 3}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:35,653]\u001b[0m Trial 58 finished with value: 0.7413771410308088 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.13224799494456, 'xgb_max_depth': 6, 'xgb_min_child_weight': 15}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:37,846]\u001b[0m Trial 59 finished with value: 0.7296136920661305 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.4912707948418329, 'xgb_max_depth': 9, 'xgb_min_child_weight': 5}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:45,377]\u001b[0m Trial 60 finished with value: 0.6986293957308378 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.3408790561125652, 'hist_max_iter': 200, 'hist_max_leaf_nodes': 115}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:47,271]\u001b[0m Trial 61 finished with value: 0.6996870793881457 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.3324705496555009, 'hist_max_iter': 43, 'hist_max_leaf_nodes': 146}. Best is trial 1 with value: 0.7535292616066737.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:47,923]\u001b[0m Trial 62 finished with value: 0.7541784188737118 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.2760659810861274, 'xgb_max_depth': 2, 'xgb_min_child_weight': 2}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:48,238]\u001b[0m Trial 63 finished with value: 0.7396591312250475 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.22263124476538237, 'hist_max_iter': 40, 'hist_max_leaf_nodes': 10}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:49,651]\u001b[0m Trial 64 finished with value: 0.7421082661479234 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.3897326254646931, 'xgb_max_depth': 6, 'xgb_min_child_weight': 9}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:55,375]\u001b[0m Trial 65 finished with value: 0.5 and parameters: {'classifier': 'rf', 'rf_n_estimators': 813, 'rf_criterion': 'entropy', 'rf_max_depth': 1, 'rf_min_samples_split': 0.7164088089941517}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:16:59,070]\u001b[0m Trial 66 finished with value: 0.7186702085833385 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.28300309915469524, 'xgb_max_depth': 13, 'xgb_min_child_weight': 1}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:17:02,982]\u001b[0m Trial 67 finished with value: 0.720203605646404 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.32304744104641914, 'xgb_max_depth': 14, 'xgb_min_child_weight': 1}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:17:11,354]\u001b[0m Trial 68 finished with value: 0.6966656831448772 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.44370459988810895, 'hist_max_iter': 222, 'hist_max_leaf_nodes': 110}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:17:14,617]\u001b[0m Trial 69 finished with value: 0.5 and parameters: {'classifier': 'rf', 'rf_n_estimators': 462, 'rf_criterion': 'entropy', 'rf_max_depth': 2, 'rf_min_samples_split': 0.9223063084886817}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:17:15,420]\u001b[0m Trial 70 finished with value: 0.7526992897244168 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.028291474518894574, 'xgb_max_depth': 3, 'xgb_min_child_weight': 15}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:17:17,091]\u001b[0m Trial 71 finished with value: 0.7114414818361882 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.16747029756732199, 'hist_max_iter': 86, 'hist_max_leaf_nodes': 41}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:17:18,494]\u001b[0m Trial 72 finished with value: 0.7442016942848535 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.39994392229818154, 'xgb_max_depth': 5, 'xgb_min_child_weight': 14}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:17:24,529]\u001b[0m Trial 73 finished with value: 0.5 and parameters: {'classifier': 'rf', 'rf_n_estimators': 657, 'rf_criterion': 'gini', 'rf_max_depth': 2, 'rf_min_samples_split': 0.9802719991485788}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:17:31,657]\u001b[0m Trial 74 finished with value: 0.6853183133410852 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.4026488083255689, 'hist_max_iter': 218, 'hist_max_leaf_nodes': 138}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:17:36,298]\u001b[0m Trial 75 finished with value: 0.6965403549361678 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.24793969029095178, 'hist_max_iter': 157, 'hist_max_leaf_nodes': 69}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:17:42,299]\u001b[0m Trial 76 finished with value: 0.7394698948941836 and parameters: {'classifier': 'rf', 'rf_n_estimators': 643, 'rf_criterion': 'entropy', 'rf_max_depth': 2, 'rf_min_samples_split': 0.12058014238152616}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:17:46,010]\u001b[0m Trial 77 finished with value: 0.7381199836401298 and parameters: {'classifier': 'rf', 'rf_n_estimators': 426, 'rf_criterion': 'gini', 'rf_max_depth': 2, 'rf_min_samples_split': 0.2822058547299}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:17:46,639]\u001b[0m Trial 78 finished with value: 0.7071124149982474 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.38142296853956437, 'hist_max_iter': 60, 'hist_max_leaf_nodes': 17}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:17:51,455]\u001b[0m Trial 79 finished with value: 0.707399870781712 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.24487211947316012, 'hist_max_iter': 109, 'hist_max_leaf_nodes': 144}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:17:53,485]\u001b[0m Trial 80 finished with value: 0.5 and parameters: {'classifier': 'rf', 'rf_n_estimators': 275, 'rf_criterion': 'gini', 'rf_max_depth': 3, 'rf_min_samples_split': 0.9141057616856234}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:17:55,012]\u001b[0m Trial 81 finished with value: 0.7072011518177265 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.21273052151052108, 'hist_max_iter': 186, 'hist_max_leaf_nodes': 15}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:17:59,375]\u001b[0m Trial 82 finished with value: 0.7221248069024528 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.060371297514350136, 'hist_max_iter': 99, 'hist_max_leaf_nodes': 129}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:01,016]\u001b[0m Trial 83 finished with value: 0.7125880942947945 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.23915320306900534, 'hist_max_iter': 36, 'hist_max_leaf_nodes': 114}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:05,582]\u001b[0m Trial 84 finished with value: 0.7331650074152904 and parameters: {'classifier': 'rf', 'rf_n_estimators': 535, 'rf_criterion': 'gini', 'rf_max_depth': 4, 'rf_min_samples_split': 0.4480576855946866}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:08,257]\u001b[0m Trial 85 finished with value: 0.7307989074186959 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.3177328782451038, 'xgb_max_depth': 14, 'xgb_min_child_weight': 9}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:13,559]\u001b[0m Trial 86 finished with value: 0.6925311194112155 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.362775790517525, 'hist_max_iter': 194, 'hist_max_leaf_nodes': 62}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:14,990]\u001b[0m Trial 87 finished with value: 0.712696155854441 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.25019824865256635, 'hist_max_iter': 29, 'hist_max_leaf_nodes': 128}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:17,694]\u001b[0m Trial 88 finished with value: 0.7231675763266914 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.25640726336246417, 'xgb_max_depth': 10, 'xgb_min_child_weight': 2}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:20,057]\u001b[0m Trial 89 finished with value: 0.7201019697347444 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.037893496150739364, 'xgb_max_depth': 9, 'xgb_min_child_weight': 2}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:22,155]\u001b[0m Trial 90 finished with value: 0.7214231461662366 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.14305551847532655, 'xgb_max_depth': 8, 'xgb_min_child_weight': 2}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:28,138]\u001b[0m Trial 91 finished with value: 0.6956042182575409 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.3275996461881177, 'hist_max_iter': 205, 'hist_max_leaf_nodes': 68}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:29,866]\u001b[0m Trial 92 finished with value: 0.7286901016493873 and parameters: {'classifier': 'xgb', 'xgb_eta': 0.36466272341398465, 'xgb_max_depth': 7, 'xgb_min_child_weight': 4}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:35,689]\u001b[0m Trial 93 finished with value: 0.7352332451890725 and parameters: {'classifier': 'rf', 'rf_n_estimators': 694, 'rf_criterion': 'gini', 'rf_max_depth': 3, 'rf_min_samples_split': 0.47305099777345616}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:37,080]\u001b[0m Trial 94 finished with value: 0.7493055426467461 and parameters: {'classifier': 'rf', 'rf_n_estimators': 119, 'rf_criterion': 'entropy', 'rf_max_depth': 4, 'rf_min_samples_split': 0.09226456509469635}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:39,632]\u001b[0m Trial 95 finished with value: 0.5 and parameters: {'classifier': 'rf', 'rf_n_estimators': 352, 'rf_criterion': 'entropy', 'rf_max_depth': 4, 'rf_min_samples_split': 0.7735725411680027}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:41,690]\u001b[0m Trial 96 finished with value: 0.7132652442635604 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.11945036137542037, 'hist_max_iter': 146, 'hist_max_leaf_nodes': 29}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:47,157]\u001b[0m Trial 97 finished with value: 0.6900407820750347 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.4336312857213862, 'hist_max_iter': 147, 'hist_max_leaf_nodes': 90}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:50,598]\u001b[0m Trial 98 finished with value: 0.6974634091229914 and parameters: {'classifier': 'hist', 'hist_learning_rate': 0.3577531750906872, 'hist_max_iter': 128, 'hist_max_leaf_nodes': 60}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n",
            "\u001b[32m[I 2022-10-19 08:18:53,918]\u001b[0m Trial 99 finished with value: 0.6060119062503128 and parameters: {'classifier': 'rf', 'rf_n_estimators': 469, 'rf_criterion': 'entropy', 'rf_max_depth': 4, 'rf_min_samples_split': 0.6463053561558342}. Best is trial 62 with value: 0.7541784188737118.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Randomized Sample\n",
            "RS best params: {'classifier': 'xgb', 'xgb_eta': 0.2760659810861274, 'xgb_max_depth': 2, 'xgb_min_child_weight': 2}\n",
            "RS best score: 0.7541784188737118\n",
            "\n",
            "hist    44\n",
            "xgb     31\n",
            "rf      25\n",
            "Name: params_classifier, dtype: int64\n",
            "                       mean       std\n",
            "params_classifier                    \n",
            "hist               0.703915  0.012941\n",
            "rf                 0.627549  0.118302\n",
            "xgb                0.735063  0.012640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dv = DictVectorizer(sparse=False, sort=False)\n",
        "X_dict = X.to_dict(orient=\"records\")\n",
        "X_test_dict = X_test.to_dict(orient=\"records\")\n",
        "X = dv.fit_transform(X_dict)\n",
        "X_test = dv.transform(X_test_dict)"
      ],
      "metadata": {
        "id": "Mc8iYkX8TeRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = xgb.XGBClassifier(\n",
        "   eta=0.2760659810861274,\n",
        "   max_depth=2,\n",
        "   min_child_weight=2\n",
        ")\n",
        "model.fit(X, y)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(f\"AUC-test: {metrics.roc_auc_score(y_test, y_pred): .3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpL5R_aeToFA",
        "outputId": "d2d15581-274c-4d6d-c713-a497bf2bbec3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC-test:  0.638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uBvvet6QVAWQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}